### Project Generation Prompt for AI Developer Assistant (v3)

**Objective:**
Create a complete, well-structured Python project for an intelligent chatbot. The chatbot will feature a web UI built with Chainlit and be powered by a LangChain Agent capable of making intelligent decisions (MCP) by dynamically choosing from multiple information sources.

**Core Features:**
- **Externalized System Prompt:** The Agent's core behavior must be defined in an external text file (`prompts/chatbot_system_prompt.txt`) to allow for easy modification without changing the Python code.
- **Dual RAG System:** The Agent should have access to two distinct retrieval tools:
  1.  **Preloaded Knowledge:** On startup, the application loads all `.txt` files from a `rag_data/` directory to form a base knowledge retriever.
  2.  **On-the-fly File Processing:** The user must be able to upload files (`.txt`, `.pdf`, `.csv`) during the chat. The application will create a temporary, high-priority retriever for these files.
- **Intelligent Tool Selection:** The Agent must be prompted (via the external system prompt) to prioritize the retriever for uploaded files over the preloaded knowledge base.
- **Streaming and UI Feedback:** The entire process should be streamed to the Chainlit UI to provide clear, step-by-step feedback to the user.

**Core Technologies:**
- Python 3.10+, Chainlit, LangChain, OpenAI, FAISS (`faiss-cpu`), PyPDF, Dotenv.

---

**Project File Structure:**
Create the following file and folder structure:

```
.langchain_ChainLit/
├── .gitignore
├── Makefile
├── README.md
├── langchain_chainlit.py
├── project_prompt.txt
├── prompts/
│   └── chatbot_system_prompt.txt
├── rag_data/
├── requirements.txt
├── start.bat
└── start.sh
```

---

**Implementation Details for `langchain_chainlit.py`:**

- **Configuration Layer:** Define global constants for `RAG_DATA_FOLDER`, `LLM_MODEL_NAME`, and `CHATBOT_SYSTEM_PROMPT_PATH`.

- **Service Layer (`ChatbotService` and helpers):**
  - `process_message(self, user_message, new_files)`: The core async method that orchestrates the creation of tools, the agent executor, and streams the response.
  - `_create_agent_executor(llm, tools)`: This helper function is critical. It **must**:
    1. Read the system prompt content from the path specified in `CHATBOT_SYSTEM_PROMPT_PATH`.
    2. Include a `try...except FileNotFoundError` block. If the file is not found, it should log an error and use a simple fallback prompt.
    3. Assemble and return the `AgentExecutor` using the loaded prompt.
  - `_create_rag_retriever` and `_create_temp_retriever_from_files`: Implement the logic for creating the two types of RAG retrievers, with support for `.txt`, `.pdf`, and `.csv` in the latter.

- **Presentation Layer (Chainlit UI):**
  - Standard `@cl.on_chat_start` and `@cl.on_message` implementation. `on_message` should pass both the text content and `message.elements` to the service layer.

---

**Auxiliary File Contents:**

- **`prompts/chatbot_system_prompt.txt`:**
  - A detailed prompt written in Traditional Chinese (Taiwan) that defines the agent's role, its tools, the strategy for using them, and the required output format.

- **`requirements.txt`:**
  ```
  # LangChain and related packages
  langchain
  langchain-core
  langchain-community
  langchain-openai
  langchain-text-splitters

  # Chainlit for UI
  chainlit

  # Vector Store, Embeddings and Loaders
  faiss-cpu
  tiktoken
  pypdf

  # Environment variables
  python-dotenv
  ```

- **`Makefile`, `start.sh`, `start.bat`:**
  - Scripts to run the application using `chainlit run langchain_chainlit.py --port 8000`.
